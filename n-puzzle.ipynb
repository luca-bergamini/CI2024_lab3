{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Copyright **`(c)`** 2024 Giovanni Squillero `<giovanni.squillero@polito.it>`  \n",
    "[`https://github.com/squillero/computational-intelligence`](https://github.com/squillero/computational-intelligence)  \n",
    "Free under certain conditions — see the [`license`](https://github.com/squillero/computational-intelligence/blob/master/LICENSE.md) for details.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import functools\n",
    "from heapq import heappop, heappush\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 3\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)]\n",
    "    actions = list()\n",
    "    if x > 0:\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "def counter(fn):\n",
    "    @functools.wraps(fn)\n",
    "    def helper(*args, **kargs):\n",
    "        helper.calls += 1\n",
    "        return fn(*args, **kargs)\n",
    "\n",
    "    helper.calls = 0\n",
    "    return helper\n",
    "\n",
    "@counter\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the manhattan distance, that is the distance between the state and the goal\n",
    "def manhattan_distance(state: np.ndarray, goal: np.ndarray) -> int:\n",
    "    distance = 0\n",
    "    for num in range(1, PUZZLE_DIM**2): \n",
    "        x1, y1 = np.where(state == num)\n",
    "        x2, y2 = np.where(goal == num)\n",
    "        distance += abs(x1 - x2) + abs(y1 - y2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-star (A*) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_star(initial_state: np.ndarray, goal_state: np.ndarray) -> list['Action']:\n",
    "    # initializing the frontier as (heuristic, cost, state, path)\n",
    "    frontier = [(manhattan_distance(initial_state, goal_state), 0, tuple(initial_state.flatten()), [])]\n",
    "    visited = set()\n",
    "\n",
    "    while frontier:\n",
    "        # get the state with the lowest heuristic from the frontier\n",
    "        manh, cost, state_tuple, path = heappop(frontier)\n",
    "        state = np.array(state_tuple).reshape(PUZZLE_DIM, PUZZLE_DIM)\n",
    "        \n",
    "        # return the path if the goal is reached\n",
    "        if np.array_equal(state, goal_state):\n",
    "            return path\n",
    "        \n",
    "        # if the state_tuple is already visited, skip it\n",
    "        if state_tuple in visited:\n",
    "            continue\n",
    "\n",
    "        # add the current state_tuple in the visited set\n",
    "        visited.add(state_tuple)\n",
    "        \n",
    "        # for each action available from the current state\n",
    "        for action in available_actions(state):\n",
    "            next_state = do_action(state, action)\n",
    "            new_path = path + [action]\n",
    "            new_cost = cost + 1\n",
    "            # the new heuristic is the manhattan distance to goal + the new cost\n",
    "            new_manh = manhattan_distance(next_state, goal_state) + new_cost\n",
    "            # add the new state to the frontier\n",
    "            heappush(frontier, (new_manh, new_cost, tuple(next_state.flatten()), new_path))\n",
    "    \n",
    "    # return None if the goal is not reachable\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breadth-First Search (BFS) Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(start, goal) -> list['Action']:\n",
    "    # initializing the frontier as (state, path)\n",
    "    frontier = deque([(start, [])])\n",
    "    visited = set()\n",
    "    \n",
    "    while frontier:\n",
    "        # get the first state from the frontier\n",
    "        current, path = frontier.popleft()\n",
    "        \n",
    "        # return the path if the goal is reached\n",
    "        if np.array_equal(current, goal):\n",
    "            return path\n",
    "        \n",
    "        # if the state_tuple is already visited, skip it\n",
    "        if current is visited:\n",
    "            continue\n",
    "        \n",
    "        # add the current state_tuple in the visited set\n",
    "        visited.add(current.tobytes())\n",
    "        \n",
    "        # for each action available from the current state\n",
    "        for act in available_actions(current):\n",
    "            next_state = do_action(current, act)\n",
    "            # add the new state if has not been visited\n",
    "            if next_state.tobytes() not in visited:\n",
    "                frontier.append((next_state, path + [act]))\n",
    "\n",
    "    # return None if the goal is not reachable\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the goal and randomizing the starting state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b736f9135ae847aead13e985da29b8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Randomizing:   0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RANDOMIZE_STEPS = 100_000\n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "goal = state.copy()\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a simple state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_state = goal.copy()\n",
    "tmp = test_state[2,1]\n",
    "test_state[2,1] = test_state[2,2]\n",
    "test_state[2,2] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing A* with a simple state (only one action is needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state: [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 0 8]]\n",
      "Path: [Action(pos1=(2, 1), pos2=(2, 2))]\n",
      "Goal: [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 0]]\n",
      "Action count: 3\n"
     ]
    }
   ],
   "source": [
    "do_action.calls = 0\n",
    "path = a_star(test_state, goal)\n",
    "print(f'Starting state: {test_state}')\n",
    "print(f'Path: {path}')\n",
    "print(f'Goal: {goal}')\n",
    "print(f'Action count: {do_action.calls}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing A* with a real state (more than one action are needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state: [[2 5 4]\n",
      " [3 8 1]\n",
      " [6 7 0]]\n",
      "Path: [Action(pos1=(2, 2), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(1, 0)), Action(pos1=(1, 0), pos2=(2, 0)), Action(pos1=(2, 0), pos2=(2, 1)), Action(pos1=(2, 1), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(2, 2)), Action(pos1=(2, 2), pos2=(2, 1)), Action(pos1=(2, 1), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(0, 1)), Action(pos1=(0, 1), pos2=(0, 2)), Action(pos1=(0, 2), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(2, 2)), Action(pos1=(2, 2), pos2=(2, 1)), Action(pos1=(2, 1), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(1, 0)), Action(pos1=(1, 0), pos2=(0, 0)), Action(pos1=(0, 0), pos2=(0, 1)), Action(pos1=(0, 1), pos2=(0, 2)), Action(pos1=(0, 2), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(1, 0)), Action(pos1=(1, 0), pos2=(0, 0)), Action(pos1=(0, 0), pos2=(0, 1)), Action(pos1=(0, 1), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(2, 1)), Action(pos1=(2, 1), pos2=(2, 2))]\n",
      "Path length: 28\n",
      "Goal: [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 0]]\n",
      "Action count: 20948\n"
     ]
    }
   ],
   "source": [
    "do_action.calls = 0\n",
    "path = a_star(state, goal)\n",
    "print(f'Starting state: {state}')\n",
    "print(f'Path: {path}')\n",
    "print(f'Path length: {len(path)}')\n",
    "print(f'Goal: {goal}')\n",
    "print(f'Action count: {do_action.calls}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing BFS (Breadth-First Search) with a simple state (only one action is needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state: [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 0 8]]\n",
      "Path: [Action(pos1=(2, 1), pos2=(2, 2))]\n",
      "Goal: [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 0]]\n",
      "Action count: 9\n"
     ]
    }
   ],
   "source": [
    "do_action.calls = 0\n",
    "path = bfs(test_state, goal)\n",
    "print(f'Starting state: {test_state}')\n",
    "print(f'Path: {path}')\n",
    "print(f'Goal: {goal}')\n",
    "print(f'Action count: {do_action.calls}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing BFS (Breadth-First Search) with a real state (more than one action are needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting state: [[2 5 4]\n",
      " [3 8 1]\n",
      " [6 7 0]]\n",
      "Path: [Action(pos1=(2, 2), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(2, 1)), Action(pos1=(2, 1), pos2=(2, 0)), Action(pos1=(2, 0), pos2=(1, 0)), Action(pos1=(1, 0), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(2, 1)), Action(pos1=(2, 1), pos2=(2, 2)), Action(pos1=(2, 2), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(2, 1)), Action(pos1=(2, 1), pos2=(2, 0)), Action(pos1=(2, 0), pos2=(1, 0)), Action(pos1=(1, 0), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(2, 1)), Action(pos1=(2, 1), pos2=(2, 2)), Action(pos1=(2, 2), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(0, 2)), Action(pos1=(0, 2), pos2=(0, 1)), Action(pos1=(0, 1), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(0, 2)), Action(pos1=(0, 2), pos2=(0, 1)), Action(pos1=(0, 1), pos2=(0, 0)), Action(pos1=(0, 0), pos2=(1, 0)), Action(pos1=(1, 0), pos2=(1, 1)), Action(pos1=(1, 1), pos2=(1, 2)), Action(pos1=(1, 2), pos2=(2, 2))]\n",
      "Path length: 28\n",
      "Goal: [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 0]]\n",
      "Action count: 1250460\n"
     ]
    }
   ],
   "source": [
    "do_action.calls = 0\n",
    "path = bfs(state, goal)\n",
    "print(f'Starting state: {state}')\n",
    "print(f'Path: {path}')\n",
    "print(f'Path length: {len(path)}')\n",
    "print(f'Goal: {goal}')\n",
    "print(f'Action count: {do_action.calls}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ci-3rwch_zL-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
